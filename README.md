# üö® **Syst√®me de D√©tection de Fraude Bancaire en Temps R√©el**

> Architecture Big Data compl√®te pour l'analyse transactionnelle en temps r√©el utilisant Kafka, Spark Streaming et Elasticsearch

[![Python](https://img.shields.io/badge/Python-3.11-blue.svg)](https://www.python.org/)
[![Spark](https://img.shields.io/badge/Apache_Spark-3.5.1-orange.svg)](https://spark.apache.org/)
[![Kafka](https://img.shields.io/badge/Apache_Kafka-3.4.1-black.svg)](https://kafka.apache.org/)
[![Elasticsearch](https://img.shields.io/badge/Elasticsearch-8.15.0-green.svg)](https://www.elastic.co/)
[![Docker](https://img.shields.io/badge/Docker-Containers-blue.svg)](https://www.docker.com/)

## üìã **Aper√ßu du Projet**

Ce projet impl√©mente un syst√®me complet de d√©tection de fraude bancaire fonctionnant en **temps r√©el**. 
Il simule, traite et analyse des transactions financi√®res pour identifier les activit√©s suspectes en moins de 2 secondes.

### **‚ú® Fonctionnalit√©s Principales**
- ‚úÖ **Simulation r√©aliste** de transactions avec patterns de fraude int√©gr√©s
- ‚úÖ **D√©tection en temps r√©el** avec latence < 2 secondes
- ‚úÖ **Dashboard interactif** avec Kibana pour la visualisation
- ‚úÖ **Architecture conteneuris√©e** pr√™te √† l'ex√©cution
- ‚úÖ **Monitoring complet** via Spark UI et logs
- ‚úÖ **Scalabilit√© horizontale** con√ßue pour 10K+ transactions/sec

### **Composants**
1. **Producer** : G√©n√®re des transactions bancaires r√©alistes
2. **Kafka** : Bus de messages pour l'ingestion des donn√©es
3. **Spark Streaming** : Traitement distribu√© des transactions
4. **Elasticsearch** : Stockage et indexation des alertes
5. **Kibana** : Visualisation et dashboarding
6. **Zookeeper** : Coordination du cluster Kafka

## üöÄ **D√©marrage Rapide**

### **Pr√©requis**
- Docker et Docker Compose install√©s
- 4GB de RAM minimum
- Python 3.11 (optionnel, pour d√©veloppement)

### **Installation en 5 minutes**

# 1. Clonez le repository
git clone https://github.com/BrinsiAmal/fraud-detection-project.git
cd fraud-detection-project

# 2. D√©marrez tous les services
docker-compose up -d

# 3. V√©rifiez que tous les services tournent
docker-compose ps

# 4. Acc√©dez aux interfaces
#    ‚Ä¢ Kibana : http://localhost:5601
#    ‚Ä¢ Spark UI : http://localhost:4040
#    ‚Ä¢ Elasticsearch : http://localhost:9200
